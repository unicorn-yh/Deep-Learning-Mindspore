{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 花卉图像分类实验"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验介绍"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本实验主要介绍如何使用MindSpore进行花卉图像分类实验。定义卷积神经网络，并利于该网络进行花卉分类训练和测试。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验目的"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 掌握如何使用MindSpore进行卷积神经网络的开发。\n",
    "- 了解如何使用MindSpore进行花卉图片分类任务的训练。\n",
    "- 了解如何使用MindSpore进行花卉图片分类任务的测试。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备知识"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 熟练使用Python。\n",
    "- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n",
    "- 了解华为云的基本使用方法，包括[训练作业](https://support.huaweicloud.com/engineers-modelarts/modelarts_23_0046.html)等功能。华为云官网：https://www.huaweicloud.com\n",
    "- 了解并熟悉MindSpore AI计算框架，MindSpore官网：https://www.mindspore.cn/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验环境"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MindSpore 1.2（MindSpore版本会定期更新，本指导也会定期刷新，与版本配套）；\n",
    "- 华为云ModelArts：ModelArts是华为云提供的面向开发者的一站式AI开发平台，集成了昇腾AI处理器资源池，用户可以在该平台下体验MindSpore。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集准备"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flower_photos共五种鲜花的图片数据，分别为雏菊（daisy ）、蒲公英（dandelion）、玫瑰花（roses）、向日葵(sunflowers)、郁金香（tulips），其中每种约800张图像数据，共计约3670张，可用于深度学习图像分类练习使用，可以在[这里](https://hciaai.obs.cn-north-4.myhuaweicloud.com:443/flower_photos.zip)下载数据集，并解压到本地。\n",
    "\n",
    "```\n",
    "daisy           633张     \n",
    "dandelion       898张\n",
    "roses           641张\n",
    "sunflowers      699张  \n",
    "tulips          799张\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验步骤"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入MindSpore模块和辅助模块"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用到的框架主要包括：MindSpore，主要用于深度学习算法的构建，这里主要用于卷积神经网络的搭建，主要以开源的花类数据集为基础，基MindSpore深度学习框架和卷积神经网络（CNN）对花的类型进行分类识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#easydict模块用于以属性的方式访问字典的值\n",
    "from easydict import EasyDict as edict\n",
    "#glob模块主要用于查找符合特定规则的文件路径名，类似使用windows下的文件搜索\n",
    "import glob\n",
    "#os模块主要用于处理文件和目录\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mindspore\n",
    "#导入mindspore框架数据集\n",
    "import mindspore.dataset as ds\n",
    "#vision.c_transforms模块是处理图像增强的高性能模块，用于数据增强图像数据改进训练模型。\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "#c_transforms模块提供常用操作，包括OneHotOp和TypeCast\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "from mindspore.common import dtype as mstype\n",
    "from mindspore import context\n",
    "#导入模块用于初始化截断正态分布\n",
    "from mindspore.common.initializer import TruncatedNormal\n",
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore import Tensor\n",
    "# 设置MindSpore的执行模式和设备\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变量定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = edict({\n",
    "    'data_path': 'flower_photos',\n",
    "    'data_size':3670,\n",
    "    'image_width': 100,  # 图片宽度\n",
    "    'image_height': 100,  # 图片高度\n",
    "    'batch_size': 32,\n",
    "    'channel': 3,  # 图片通道数\n",
    "    'num_class':5,  # 分类类别\n",
    "    'weight_decay': 0.01,\n",
    "    'lr': 0.0001,  # 学习率\n",
    "    'dropout_ratio': 0.5,\n",
    "    'epoch_size': 400,  # 训练次数\n",
    "    'sigma': 0.01,\n",
    "    'save_checkpoint_steps': 1,  # 多少步保存一次模型\n",
    "    'keep_checkpoint_max': 3,  # 最多保存多少个模型\n",
    "    'output_directory': './code/flowers//model',  # 保存模型路径\n",
    "    'output_prefix': \"checkpoint_classification\"  # 保存模型文件名字\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取并处理数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取并处理流程如下：\n",
    "- (1)MindSpore的mindspore.dataset提供了ImageFolderDatasetV2函数，这里我们使用该函数读取'daisy','dandelion','roses','sunflowers','tulips'数据，并将这五类标签映射。\n",
    "- (2)使用RandomCropDecodeResize、HWC2CHW、TypeCast、shuffle进行数据预处理\n",
    "- (3)按照8:2的比列将数据划分为训练数据集和测试数据集\n",
    "- (4)对训练数据和测试数据分批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-24 21:21:05--  https://ascend-professional-construction-dataset.obs.myhuaweicloud.com/deep-learning/flower_photos.zip\n",
      "Resolving proxy.modelarts.com (proxy.modelarts.com)... 192.168.6.3\n",
      "Connecting to proxy.modelarts.com (proxy.modelarts.com)|192.168.6.3|:80... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 229618046 (219M) [application/zip]\n",
      "Saving to: ‘flower_photos.zip.1’\n",
      "\n",
      "flower_photos.zip.1 100%[===================>] 218.98M   269MB/s    in 0.8s    \n",
      "\n",
      "2023-03-24 21:21:06 (269 MB/s) - ‘flower_photos.zip.1’ saved [229618046/229618046]\n",
      "\n",
      "Archive:  flower_photos.zip\n",
      "replace flower_photos/daisy/100080576_f52e8ee070_n.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "# 解压数据集，只需要第一次运行时解压，第二次无需再解压\n",
    "!wget https://ascend-professional-construction-dataset.obs.myhuaweicloud.com/deep-learning/flower_photos.zip \n",
    "!unzip flower_photos.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "#读取图像的源数据集。\n",
    "de_dataset = ds.ImageFolderDataset(cfg.data_path, class_indexing={'daisy':0,'dandelion':1,'roses':2,'sunflowers':3,'tulips':4})\n",
    "\n",
    "#(2)\n",
    "#解码前将输入图像裁剪成任意大小和宽高比。\n",
    "transform_img =  CV.RandomCropDecodeResize([cfg.image_width,cfg.image_height], scale=(0.08, 1.0), ratio=(0.75, 1.333)) #改变尺寸\n",
    "#转换输入图像形状为（C, H, W）。\n",
    "hwc2chw_op = CV.HWC2CHW()\n",
    "#转换为给定MindSpore数据类型的Tensor操作。\n",
    "type_cast_op = C.TypeCast(mstype.float32)\n",
    "#将上述三个操作应用到此数据集。\n",
    "de_dataset = de_dataset.map(input_columns=\"image\", num_parallel_workers=8, operations=transform_img)\n",
    "de_dataset = de_dataset.map(input_columns=\"image\", operations=hwc2chw_op, num_parallel_workers=8)\n",
    "de_dataset = de_dataset.map(input_columns=\"image\", operations=type_cast_op, num_parallel_workers=8)\n",
    "de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)\n",
    "\n",
    "\n",
    "#（3）\n",
    "#划分训练集测试集\n",
    "(de_train,de_test)=de_dataset.split([0.8,0.2])\n",
    "\n",
    "#（4）\n",
    "#设置每个批处理的行数\n",
    "de_train=de_train.batch(cfg.batch_size, drop_remainder=True)\n",
    "de_train=de_train.repeat(cfg.epoch_size)\n",
    "#重复此数据集计数次数。\n",
    "de_test=de_test.batch(cfg.batch_size, drop_remainder=True)\n",
    "de_test=de_test.repeat(cfg.epoch_size)\n",
    "print('训练数据集数量：',de_train.get_dataset_size()*cfg.batch_size)#get_dataset_size()获取批处理的大小。\n",
    "print('测试数据集数量：',de_test.get_dataset_size()*cfg.batch_size)\n",
    "\n",
    "data_next=de_dataset.create_dict_iterator(output_numpy=True).__next__()\n",
    "print('通道数/图像长/宽：', data_next['image'].shape)\n",
    "print('一张图像的标签样式：', data_next['label']) # 一共5类，用0-4的数字表达类别。\n",
    "plt.figure()\n",
    "plt.imshow(data_next['image'][0,...])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义CNN图像识别网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN图像识别网络\n",
    "class Identification_Net(nn.Cell):\n",
    "    def __init__(self, num_class=5,channel=3,dropout_ratio=0.5,trun_sigma=0.01):  #需补充数值\n",
    "        super(Identification_Net, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.channel = channel\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        #设置卷积层、激活函数、最大池化层等\n",
    "        self.conv1 = nn.Conv2d(self.channel, 32, kernel_size=5, stride=1, padding=0, has_bias=True, \n",
    "                               pad_mode=\"same\", weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "                               bias_init='zeros')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=0, has_bias=True, \n",
    "                               pad_mode=\"same\", weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "                               bias_init='zeros')\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0, has_bias=True, \n",
    "                               pad_mode=\"same\", weight_init=TruncatedNormal(sigma=trun_sigma),\n",
    "                               bias_init='zeros')\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0, has_bias=True, \n",
    "                               pad_mode=\"same\", weight_init=TruncatedNormal(sigma=trun_sigma), \n",
    "                               bias_init='zeros')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(6*6*128, 1024,weight_init =TruncatedNormal(sigma=trun_sigma),bias_init = 0.1)\n",
    "        self.dropout = nn.Dropout(self.dropout_ratio)\n",
    "        self.fc2 = nn.Dense(1024, 512, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1)\n",
    "        self.fc3 = nn.Dense(512, self.num_class, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1)\n",
    "\n",
    "    #构建模型\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练、测试、预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_ratio)\n",
    "\n",
    "#计算softmax交叉熵。\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "#opt\n",
    "fc_weight_params = list(filter(lambda x: 'fc' in x.name and 'weight' in x.name, net.trainable_params()))\n",
    "other_params=list(filter(lambda x: 'fc' not in x.name or 'weight' not in x.name, net.trainable_params()))\n",
    "group_params = [{'params': fc_weight_params, 'weight_decay': cfg.weight_decay},\n",
    "                {'params': other_params},\n",
    "                {'order_params': net.trainable_params()}]\n",
    "#设置Adam优化器\n",
    "net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=0.0)\n",
    "\n",
    "model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics={\"acc\"})\n",
    "loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size()*10)\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps, keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=cfg.output_prefix, directory=cfg.output_directory, config=config_ck)\n",
    "print(\"============== Starting Training ==============\")\n",
    "model.train(cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=True)\n",
    "\n",
    "# 使用测试集评估模型，打印总体准确率\n",
    "metric = model.eval(de_test)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载训练好的模型\n",
    "CKPT = './code/flowers/model/checkpoint_classification-400_91.ckpt'\n",
    "net = Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_ratio)\n",
    "load_checkpoint(CKPT, net=net)\n",
    "model = Model(net)\n",
    "\n",
    "# 进行预测\n",
    "class_names = {0:'daisy',1:'dandelion',2:'roses',3:'sunflowers',4:'tulips'}\n",
    "test_ = de_test.create_dict_iterator().__next__()\n",
    "test = Tensor(test_['image'], mindspore.float32)\n",
    "predictions = model.predict(test)\n",
    "predictions = predictions.asnumpy()\n",
    "true_label = test_['label'].asnumpy()\n",
    "\n",
    "#显示Num个样本的预测结果，并和真实结果进行对比（Num无限制）\n",
    "Num = 10\n",
    "for i in range(Num):\n",
    "    p_np = predictions[i, :]\n",
    "    p_list = p_np.tolist()\n",
    "    pre_label = class_names[p_list.index(max(p_list))]\n",
    "    true_label = class_names[test_['label']]\n",
    "    print('第' + str(i) + '个sample预测结果：', pre_label, '   真实结果：', true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
